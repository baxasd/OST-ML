{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f80acd-1fb8-4415-8946-a1a9f1c05281",
   "metadata": {},
   "source": [
    "# OST – Gait Data Preprocessing Notebook\n",
    "\n",
    "**Author:** Bakhtiyor Sohibnazarov  \n",
    "**Module:** Final Year Project  \n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads raw 3D joint data captured by the OST system.\n",
    "2. Handles timestamps and derives a clean time base.\n",
    "3. Runs data quality diagnostics:\n",
    "   - Missing data per joint\n",
    "   - Bone-length stability\n",
    "   - Basic velocity sanity check\n",
    "4. Interpolates short gaps and smooths joint trajectories using a One Euro filter.\n",
    "5. Reduces the dataset to key biomechanical joints and exports:\n",
    "   - A filtered full-joint CSV\n",
    "   - A reduced preprocessed CSV for analysis notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf9056a-e2d9-4399-beb2-f1a41dc2eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip -q install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1708307e-be05-4b67-ae13-b9567666b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS & GLOBAL CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# File paths (adjust as needed)\n",
    "# ------------------------------------------------------------\n",
    "INPUT_CSV_RAW       = \"data/28.11_raw.csv\"\n",
    "OUTPUT_CSV_FILTERED = \"output/28.11_filtered.csv\"\n",
    "OUTPUT_CSV_REDUCED  = \"output/28.11_preprocessed.csv\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Capture / timing\n",
    "# ------------------------------------------------------------\n",
    "TIMESTAMP_COLUMN    = \"timestamp\"   # set to None if no timestamp column\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Interpolation settings\n",
    "# ------------------------------------------------------------\n",
    "MAX_INTERP_GAP      = 3   # max consecutive NaN frames to interpolate\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# One Euro filter parameters\n",
    "# ------------------------------------------------------------\n",
    "MIN_CUTOFF          = 0.5    # base cutoff\n",
    "BETA                = 0.02   # speed sensitivity\n",
    "DCUTOFF             = 1.0    # derivative cutoff\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Joint indices (BlazePose-style)\n",
    "# ------------------------------------------------------------\n",
    "LEFT_HEEL_INDEX     = 29\n",
    "RIGHT_HEEL_INDEX    = 30\n",
    "LEFT_HIP_INDEX      = 23\n",
    "RIGHT_HIP_INDEX     = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09291000-687e-43c3-88a7-b63c5bbd6d95",
   "metadata": {},
   "source": [
    "## 2. Utility functions\n",
    "\n",
    "We define helpers for:\n",
    "- One Euro filter (for smooth but responsive coordinates)\n",
    "- Interpolation of short gaps\n",
    "- Joint extraction\n",
    "- Small reporting helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e94470-6699-4f56-b216-64ec3476a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. UTILITY FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def lowpass(prev, curr, alpha):\n",
    "    return alpha * curr + (1 - alpha) * prev\n",
    "\n",
    "def compute_alpha(cutoff, dt):\n",
    "    if cutoff <= 0:\n",
    "        return 1.0\n",
    "    tau = 1.0 / (2 * np.pi * cutoff)\n",
    "    return 1.0 / (1.0 + tau / dt)\n",
    "\n",
    "class OneEuroFilter:\n",
    "    \"\"\"\n",
    "    Simple One Euro filter implementation for 1D signals.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_cutoff=1.0, beta=0.0, d_cutoff=1.0):\n",
    "        self.min_cutoff = float(min_cutoff)\n",
    "        self.beta = float(beta)\n",
    "        self.d_cutoff = float(d_cutoff)\n",
    "        self.x_prev = None\n",
    "        self.dx_prev = 0.0\n",
    "        self.t_prev = None\n",
    "\n",
    "    def __call__(self, t, x):\n",
    "        # First sample → initialise\n",
    "        if self.t_prev is None:\n",
    "            self.t_prev = t\n",
    "            self.x_prev = x\n",
    "            self.dx_prev = 0.0\n",
    "            return x\n",
    "\n",
    "        dt = t - self.t_prev\n",
    "        if dt <= 0:\n",
    "            # Non-positive dt → keep previous value\n",
    "            return self.x_prev\n",
    "\n",
    "        # Raw derivative\n",
    "        dx = (x - self.x_prev) / dt\n",
    "\n",
    "        # Filter derivative\n",
    "        alpha_d = compute_alpha(self.d_cutoff, dt)\n",
    "        dx_hat = lowpass(self.dx_prev, dx, alpha_d)\n",
    "\n",
    "        # Dynamic cutoff based on derivative magnitude\n",
    "        cutoff = self.min_cutoff + self.beta * abs(dx_hat)\n",
    "        alpha = compute_alpha(cutoff, dt)\n",
    "\n",
    "        # Filter signal\n",
    "        x_hat = lowpass(self.x_prev, x, alpha)\n",
    "\n",
    "        # Update state\n",
    "        self.x_prev = x_hat\n",
    "        self.dx_prev = dx_hat\n",
    "        self.t_prev = t\n",
    "\n",
    "        return x_hat\n",
    "\n",
    "def interpolate_short_gaps(arr: np.ndarray, max_gap: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Linearly interpolates NaN gaps up to 'max_gap' in length (in samples).\n",
    "    Longer gaps are left as NaN.\n",
    "    Works on 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    arr = arr.copy()\n",
    "    n = len(arr)\n",
    "\n",
    "    nan_idx = np.where(np.isnan(arr))[0]\n",
    "    if len(nan_idx) == 0:\n",
    "        return arr\n",
    "\n",
    "    def fill_gap(start, end):\n",
    "        gap_len = end - start + 1\n",
    "        if gap_len > max_gap:\n",
    "            return\n",
    "        left = start - 1\n",
    "        right = end + 1\n",
    "        if 0 <= left < n and 0 <= right < n and not np.isnan(arr[left]) and not np.isnan(arr[right]):\n",
    "            arr[start:end+1] = np.interp(\n",
    "                np.arange(start, end+1),\n",
    "                [left, right],\n",
    "                [arr[left], arr[right]]\n",
    "            )\n",
    "\n",
    "    # Walk segments\n",
    "    start = nan_idx[0]\n",
    "    for i in range(1, len(nan_idx)):\n",
    "        if nan_idx[i] != nan_idx[i-1] + 1:\n",
    "            end = nan_idx[i-1]\n",
    "            fill_gap(start, end)\n",
    "            start = nan_idx[i]\n",
    "    # last segment\n",
    "    end = nan_idx[-1]\n",
    "    fill_gap(start, end)\n",
    "\n",
    "    return arr\n",
    "\n",
    "def get_joint_array(df: pd.DataFrame, j_idx: int) -> np.ndarray:\n",
    "    cols = [f\"joint_{j_idx}_x\", f\"joint_{j_idx}_y\", f\"joint_{j_idx}_z\"]\n",
    "    return df[cols].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef2f91-e9e4-41c8-827b-ab4dc6a9e2af",
   "metadata": {},
   "source": [
    "## 3. Load raw data and derive time base\n",
    "\n",
    "We:\n",
    "- Load the raw CSV\n",
    "- Derive `time` using timestamp if present, otherwise from frame index\n",
    "- Estimate effective FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e132ec-2ec6-462b-913e-9fb13473b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data/28.11_raw.csv\n",
      "Shape: 25410 frames x 100 columns\n",
      "Python datetime timestamps detected → parsing\n",
      "Warning: 1 non-increasing timestamps → repairing (assuming 30 FPS)\n",
      "Median Δt: 0.066509 s\n",
      "Effective FPS: 15.036 Hz\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. LOAD RAW DATA & TIME BASE\n",
    "# ============================================================\n",
    "df_raw = pd.read_csv(INPUT_CSV_RAW)\n",
    "print(f\"Loaded: {INPUT_CSV_RAW}\")\n",
    "print(f\"Shape: {df_raw.shape[0]} frames x {df_raw.shape[1]} columns\")\n",
    "\n",
    "# Detect joint columns and IDs\n",
    "joint_cols = sorted(\n",
    "    [c for c in df_raw.columns if c.startswith(\"joint_\")],\n",
    "    key=lambda x: (int(x.split(\"_\")[1]), x.split(\"_\")[2])\n",
    ")\n",
    "joint_ids = sorted({int(c.split(\"_\")[1]) for c in joint_cols})\n",
    "\n",
    "# --- Time handling ---\n",
    "if TIMESTAMP_COLUMN is not None and TIMESTAMP_COLUMN in df_raw.columns:\n",
    "    print(\"Python datetime timestamps detected → parsing\")\n",
    "\n",
    "    t_raw = pd.to_datetime(df_raw[TIMESTAMP_COLUMN], errors=\"coerce\")\n",
    "\n",
    "    if t_raw.isna().any():\n",
    "        print(\"Warning: malformed timestamps found → repairing via ffill/bfill\")\n",
    "        t_raw = t_raw.ffill().bfill()\n",
    "\n",
    "    t_sec = (t_raw - t_raw.iloc[0]).dt.total_seconds().to_numpy()\n",
    "\n",
    "    dt = np.diff(t_sec, prepend=t_sec[0])\n",
    "    bad = dt <= 0\n",
    "    if np.any(bad):\n",
    "        print(f\"Warning: {bad.sum()} non-increasing timestamps → repairing (assuming 30 FPS)\")\n",
    "        nominal_dt = 1.0 / 30.0\n",
    "        for i in range(1, len(t_sec)):\n",
    "            if t_sec[i] <= t_sec[i-1]:\n",
    "                t_sec[i] = t_sec[i-1] + nominal_dt\n",
    "\n",
    "    time = t_sec\n",
    "else:\n",
    "    print(\"No timestamp column → using synthetic time @ 30 FPS\")\n",
    "    fps_guess = 30.0\n",
    "    time = np.arange(len(df_raw)) / fps_guess\n",
    "\n",
    "df_raw[\"time\"] = time\n",
    "\n",
    "dt = np.diff(time)\n",
    "median_dt = np.nanmedian(dt)\n",
    "fps_effective = 1.0 / median_dt\n",
    "\n",
    "print(f\"Median Δt: {median_dt:.6f} s\")\n",
    "print(f\"Effective FPS: {fps_effective:.3f} Hz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6d104-c3c8-4fed-9f13-ba9f5aa22680",
   "metadata": {},
   "source": [
    "## 5. Preprocessing: interpolate short gaps & apply One Euro filter\n",
    "\n",
    "We clean the data **in place**:\n",
    "- Interpolate short NaN gaps (up to `MAX_INTERP_GAP` frames) for each joint coordinate.\n",
    "- Apply One Euro filter to each coordinate time-series.\n",
    "- Construct a `valid` mask (frames without remaining NaNs).\n",
    "- Save a filtered CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4997d959-085b-4d3a-8ba1-d0a745e5db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames valid after preprocessing: 99.95%\n",
      "Saved filtered data → output/28.11_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FAST PREPROCESSING BLOCK (NO FRAGMENTATION)\n",
    "# ============================================================\n",
    "df = df_raw.copy()\n",
    "t = df[\"time\"].to_numpy()\n",
    "\n",
    "# Store filtered columns in a dict first (fast)\n",
    "filtered_cols = {}\n",
    "\n",
    "for j in joint_ids:\n",
    "    # Create filters for each axis\n",
    "    f_x = OneEuroFilter(min_cutoff=MIN_CUTOFF, beta=BETA, d_cutoff=DCUTOFF)\n",
    "    f_y = OneEuroFilter(min_cutoff=MIN_CUTOFF, beta=BETA, d_cutoff=DCUTOFF)\n",
    "    f_z = OneEuroFilter(min_cutoff=MIN_CUTOFF, beta=BETA, d_cutoff=DCUTOFF)\n",
    "\n",
    "    for axis, f in zip([\"x\", \"y\", \"z\"], [f_x, f_y, f_z]):\n",
    "        col = f\"joint_{j}_{axis}\"\n",
    "        if col not in df:\n",
    "            continue\n",
    "\n",
    "        arr = df[col].astype(float).to_numpy()\n",
    "\n",
    "        # Interpolate short gaps\n",
    "        arr_interp = interpolate_short_gaps(arr, MAX_INTERP_GAP)\n",
    "\n",
    "        # Filter all frames\n",
    "        arr_filt = np.empty_like(arr_interp)\n",
    "        for idx, (ti, xi) in enumerate(zip(t, arr_interp)):\n",
    "            arr_filt[idx] = np.nan if np.isnan(xi) else f(ti, xi)\n",
    "\n",
    "        filtered_cols[col] = arr_filt\n",
    "\n",
    "# Build the final filtered DataFrame in one shot → no fragmentation\n",
    "filtered = pd.DataFrame(filtered_cols)\n",
    "filtered.insert(0, \"time\", t)\n",
    "\n",
    "if TIMESTAMP_COLUMN in df:\n",
    "    filtered.insert(1, TIMESTAMP_COLUMN, df[TIMESTAMP_COLUMN])\n",
    "\n",
    "# Valid frame mask\n",
    "joint_cols_filt = [c for c in filtered.columns if c.startswith(\"joint_\")]\n",
    "valid_mask = ~filtered[joint_cols_filt].isna().any(axis=1)\n",
    "filtered[\"valid\"] = valid_mask\n",
    "\n",
    "print(f\"Frames valid after preprocessing: {valid_mask.mean()*100:.2f}%\")\n",
    "\n",
    "filtered.to_csv(OUTPUT_CSV_FILTERED, index=False)\n",
    "print(f\"Saved filtered data → {OUTPUT_CSV_FILTERED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f34996-b18e-450d-8855-c21c3c619f79",
   "metadata": {},
   "source": [
    "## 6. Reduce to key joints and export preprocessed dataset\n",
    "\n",
    "To keep files compact and analysis-focused, we save only:\n",
    "- Time, optional timestamp\n",
    "- Selected biomechanically relevant joints\n",
    "- Validity mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd3864c8-06be-48e8-95ff-943f19b1d5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reduced dataset → output/28.11_preprocessed.csv\n",
      "Shape: (25410, 48)\n",
      "Valid frames in reduced set: 99.95%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. JOINT REDUCTION & EXPORT\n",
    "# ============================================================\n",
    "\n",
    "KEEP = [\n",
    "    0,      # Head\n",
    "    11,12,  # Shoulders\n",
    "    13,14,  # Elbows\n",
    "    15,16,  # Wrists\n",
    "    23,24,  # Hips\n",
    "    25,26,  # Knees\n",
    "    27,28,  # Ankles\n",
    "    29,30,  # Heels\n",
    "]\n",
    "\n",
    "keep_cols = []\n",
    "for j in KEEP:\n",
    "    for axis in [\"x\", \"y\", \"z\"]:\n",
    "        col = f\"joint_{j}_{axis}\"\n",
    "        if col in filtered.columns:\n",
    "            keep_cols.append(col)\n",
    "        else:\n",
    "            print(f\"Warning: missing joint column → {col}\")\n",
    "\n",
    "base_cols = [\"time\"]\n",
    "if TIMESTAMP_COLUMN is not None and TIMESTAMP_COLUMN in filtered.columns:\n",
    "    base_cols.append(TIMESTAMP_COLUMN)\n",
    "\n",
    "final_reduced = filtered[base_cols + keep_cols + [\"valid\"]].copy()\n",
    "final_reduced.to_csv(OUTPUT_CSV_REDUCED, index=False)\n",
    "\n",
    "print(f\"Saved reduced dataset → {OUTPUT_CSV_REDUCED}\")\n",
    "print(f\"Shape: {final_reduced.shape}\")\n",
    "print(f\"Valid frames in reduced set: {final_reduced['valid'].mean()*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
